{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf_arm': conda)"
  },
  "interpreter": {
   "hash": "aad12466045a1575aa1be41a0534cd7508fda1531bcc5a3693dc9ed3be064607"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dense, Flatten, Reshape\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "DATA_FILE = \"x.npy\"\n",
    "\n",
    "batch_size = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data\n",
    "Load data and split it into batches. Split into batches because the model(s) has/have a custom training loop and is trained one batch at a time so splitting the data now makes it a little easier later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "x = np.load(DATA_FILE)\n",
    "img_shape = x.shape[1:]\n",
    "x = np.split(x[:len(x)//batch_size * batch_size], len(x)//batch_size)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keep track of tensors and layers becuase layers are used to define `Sequential` models and tensors are used to define the input and output of `Model` models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "encoder_conv_tensors = []\n",
    "encoder_conv_layers = []\n",
    "\n",
    "decoder_conv_tensors = []\n",
    "decoder_conv_layers = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the Models\n",
    "Imagine the autoencoder as a U shape, with the top two points in the U being the first layer of the encoder and the last layer of the decoder. The layers are created starting at the top of the U, going down."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "input_tensor = Input(shape=img_shape)\n",
    "\n",
    "num_layers = int(math.log2(img_shape[0])) # All layers have a stride of 2 and the images are preprocessed to be squares with a power of two side length\n",
    "                                          # so `num_layers` layers will reduce the images down to a 1x1 feature stack\n",
    "for i in range(num_layers):\n",
    "    num_encoder_filters = 3*2**(i+1)\n",
    "    num_decoder_filters = 3*2**i\n",
    "    if i == 0:\n",
    "        encoder_layer = Conv2D(num_encoder_filters, 5, strides=2, padding=\"same\", activation='selu')\n",
    "        encoder_tensor = encoder_layer(input_tensor)\n",
    "        decoder_layer = Conv2DTranspose(3, 5, strides=2, padding=\"same\", activation='sigmoid')\n",
    "        decoder_tensor = decoder_layer(encoder_tensor)\n",
    "    else:\n",
    "        encoder_layer = Conv2D(num_encoder_filters, 3, strides=2, padding=\"same\", activation='selu')\n",
    "        encoder_tensor = encoder_layer(encoder_conv_tensors[-1])\n",
    "        decoder_layer = Conv2DTranspose(num_decoder_filters, 3, strides=2, padding=\"same\", activation='selu')\n",
    "        decoder_tensor = decoder_layer(encoder_tensor)\n",
    "    \n",
    "    encoder_conv_tensors.append(encoder_tensor)\n",
    "    encoder_conv_layers.append(encoder_layer)\n",
    "\n",
    "    decoder_conv_tensors.append(decoder_tensor)\n",
    "    decoder_conv_layers.append(decoder_layer)\n",
    "\n",
    "decoder_conv_layers.reverse()\n",
    "\n",
    "encoder = Sequential(encoder_conv_layers)\n",
    "decoder = Sequential(decoder_conv_layers)\n",
    "\n",
    "autoencoder = Sequential([encoder, decoder])\n",
    "autoencoder = keras.models.clone_model(autoencoder)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"MSE\", metrics=[\"mean_absolute_error\"])\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def train_step(batch):\n",
    "    autoencoder.train_on_batch(batch, batch)\n",
    "\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    print(\"\\nEpoch %d/%d\" % (i, epochs))\n",
    "    for batch in tqdm(x):\n",
    "        train_step(batch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch 0/10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/413 [00:00<?, ?it/s]2021-10-05 17:42:31.636053: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-05 17:42:31.640461: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# encoding_depth = 0\n",
    "\n",
    "display_images = x[0][:10]\n",
    "\n",
    "basic_reconstructions = autoencoder.predict(display_images)\n",
    "\n",
    "fig, axs = plt.subplots(5, 3)\n",
    "\n",
    "titles = [\"Original\", \"Stacked\"]\n",
    "\n",
    "for r, row in enumerate(axs):\n",
    "    imgs = [x[0][r], basic_reconstructions[r]]\n",
    "    for c, ax in enumerate(row):\n",
    "        img = imgs[c].astype(float)\n",
    "        ax.imshow(img)\n",
    "        if r == 0:\n",
    "            ax.set_title(titles[c])\n",
    "\n",
    "fig.set_size_inches(6, 9)\n",
    "fig.savefig(\"stacked.png\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# recursive_autoencoder.save(\"models/R_7_384.h5\")\n",
    "# autoencoder.save(\"models/S_7_384.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}